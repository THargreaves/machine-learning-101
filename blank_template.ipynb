{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "through-aging",
   "metadata": {},
   "source": [
    "# Machine Learning 101 | WarwickHACK 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-adult",
   "metadata": {},
   "source": [
    "**A competed version of this notebook can be found [here](https://colab.research.google.com/github/THargreaves/machine-learning-101/blob/master/blank_template.ipynb).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-source",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-usage",
   "metadata": {},
   "source": [
    "### Where Am I?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-operations",
   "metadata": {},
   "source": [
    "[Google Colab](https://colab.research.google.com/) is an online platform for running Python code without needing to install any software. You just need to sign in with a Google account and you're good to go. All _notebooks_ are saved to your Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-checkout",
   "metadata": {},
   "source": [
    "### Session Content\n",
    "\n",
    "- What is machine learning?\n",
    "- Decision trees and random forests\n",
    "- Fitting a machine learning model\n",
    "- Model tuning and measuring performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-mustang",
   "metadata": {},
   "source": [
    "### Teaching Style\n",
    "\n",
    "- Interactive\n",
    "- Practical\n",
    "- Light\n",
    "- Focus on exploration rather than memorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-status",
   "metadata": {},
   "source": [
    "### Warwick Data Science Society"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-reducing",
   "metadata": {},
   "source": [
    "![WDSS banner](images/wdss_banner.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-warrior",
   "metadata": {},
   "source": [
    "Follow WDSS on [Facebook](https://link.wdss.io/facebook), [LinkedIn](https://link.wdss.io/linkedin), and [YouTube](https://link.wdss.io/youtube) for:\n",
    "- Numerous high-quality, free teaching courses on Python, R, Julia, SQL, etc.\n",
    "- Regular events with high-profile speakers from academia and industry\n",
    "- Student-led talks and workshops\n",
    "- Interdisciplinary research projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-reset",
   "metadata": {},
   "source": [
    "Elections are coming up and there are many non-technical roles. Check them out [here](https://www.facebook.com/warwickdatasciencesociety/posts/573623496854004)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-essex",
   "metadata": {},
   "source": [
    "Structure:\n",
    "- Introduction/promotion of WDSS\n",
    "- What is machine learning?\n",
    "- Decision trees and random forests\n",
    "- Preparing our data\n",
    "- How do we know our model is working?\n",
    "- Who can get the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-prototype",
   "metadata": {},
   "source": [
    "### More Like This"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-retirement",
   "metadata": {},
   "source": [
    "- [Python and a Piece of Paper](https://github.com/THargreaves/python-and-a-piece-of-paper) with Warwick Women in Finance\n",
    "- WDSS [Data Science Beginner's Tasters](https://www.youtube.com/playlist?list=PLZOhGHnc4_7E8HwYWomqwBUXEnv4rqTWc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-delight",
   "metadata": {},
   "source": [
    "## What is Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-depth",
   "metadata": {},
   "source": [
    "_How much do you know about machine learning?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-invalid",
   "metadata": {},
   "source": [
    "### At a High Level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-original",
   "metadata": {},
   "source": [
    "Algorithms based on statistical methods to automatically find patterns and trends in data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-specialist",
   "metadata": {},
   "source": [
    "Examples:\n",
    "- Recommendation systems\n",
    "- Computer vision\n",
    "- Reinforcement learning\n",
    "- Dimensionality reduction\n",
    "- Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-carroll",
   "metadata": {},
   "source": [
    "### Machine Learning Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-facing",
   "metadata": {},
   "source": [
    "There are loosely two (main) types of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-hughes",
   "metadata": {},
   "source": [
    "|   Characteristics   |       Supervised Learning      |           Unsupervised Learning          |\n",
    "|:-------------------:|:------------------------------:|:----------------------------------------:|\n",
    "|   **Data Source**   |    Learn from labelled data    |        Learn from unlabelled data        |\n",
    "|    **Objective**    | Predicting labels for new data | Finding patterns/trends in existing data |\n",
    "|     **Example**     |        Image recognition       |           Clustering customers           |\n",
    "|    **Popularity**   |    Well-studied and utilised   |    Less popular but full of potential    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-membership",
   "metadata": {},
   "source": [
    "![](images/learning_types.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-north",
   "metadata": {},
   "source": [
    "_Image source: [lawtomated.com](https://lawtomated.com/)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-spread",
   "metadata": {},
   "source": [
    "In this session we will be focusing on supervised learning.\n",
    "\n",
    "We can further split supervised learning into two (main) categories:\n",
    "\n",
    "1. **Regression**: Predicting a continuous value such as the price of a car\n",
    "2. **Classification**: Predicting a category such as type of house"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-perth",
   "metadata": {},
   "source": [
    "![](images/supervised_types.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-twenty",
   "metadata": {},
   "source": [
    "_Image source: [javatpoint](https://www.javatpoint.com/)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-magnet",
   "metadata": {},
   "source": [
    "_Any other examples?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-picnic",
   "metadata": {},
   "source": [
    "When performing supervised machine learning, we aim to learn how to predict a label for each data point. We call the value we are trying to predict the response variable and the values we are using to predict with the predictor variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-cooling",
   "metadata": {},
   "source": [
    "## Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-magic",
   "metadata": {},
   "source": [
    "There are many machine learning models to choose from, but we will focus on one known as random forests for the following reasons:\n",
    "- Can be applied to both regression and classification\n",
    "- Works for a wide variety of data types\n",
    "- Performs well without much tuning of model\n",
    "- Generalises fairly well to unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-siemens",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-wichita",
   "metadata": {},
   "source": [
    "![](images/decision_trees.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-avenue",
   "metadata": {},
   "source": [
    "_Image source: [displayr.com](https://www.displayr.com/)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-filling",
   "metadata": {},
   "source": [
    "The decision tree above was generated manually. The goal of a decision tree machine learning model is to learn what the best tree is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-vienna",
   "metadata": {},
   "source": [
    "> **Technical Detail**\n",
    ">\n",
    "> How is this done?\n",
    "> \n",
    "> Figure out which variable has the most potential to split the labels of the data and then find the optimal split. Wash-rinse-repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-hopkins",
   "metadata": {},
   "source": [
    "[Visual walkthrough](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-johns",
   "metadata": {},
   "source": [
    "Decision trees can also be used for regression. In this case, each \"leaf\" has a number rather than a category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-dispatch",
   "metadata": {},
   "source": [
    "Problems with decision trees: potential to _overfit_ and memorise the data they are trained with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-thailand",
   "metadata": {},
   "source": [
    "![](images/overfitting_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-viewer",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-marijuana",
   "metadata": {},
   "source": [
    "Random forests are, as the name suggests, a collection of decision trees:\n",
    "\n",
    "- Each tree is trained on only a subset of the predictors and the observations\n",
    "- Makes it harder to memorise data and overfit\n",
    "- When new observations are provided, each tree _votes_ on what they think the label is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-activation",
   "metadata": {},
   "source": [
    "More trees generally result in better predictions (flattening out in the limit) but take longer to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-wireless",
   "metadata": {},
   "source": [
    "## Fitting a Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-uganda",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-investigation",
   "metadata": {},
   "source": [
    "Why reinvent the wheel? Python comes with an incredible array of packages for data manipulation, visualisation and machine learning. We just have to import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # maths\n",
    "import pandas as pd  # data manipulation\n",
    "import matplotlib.pyplot as plt  # visualisation\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-worse",
   "metadata": {},
   "source": [
    "When using Python, we need to be aware of the following facts:\n",
    "- Python is case-sensitive\n",
    "- Python generally doesn't care about spaces and newlines\n",
    "- We can run a code cell using the play button or `ctrl-enter`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-pocket",
   "metadata": {},
   "source": [
    "### The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-saver",
   "metadata": {},
   "source": [
    "In this session we will look at a dataset giving numerous characteristics of US adults and whether they earn over \\$50K. This is taken from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult) but a cleaned and processed version can be found [here](https://github.com/THargreaves/machine-learning-101/raw/master/adult.csv). You need to download this to you computer and upload it to Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names not included in dataset so we add them manually\n",
    "column_names = (\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "    'income'\n",
    ")\n",
    "# Import the dataset and save it as `income_df`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-democrat",
   "metadata": {},
   "source": [
    "The dataset comes with two columns that we don't need, `fnlwgt` and `education`. Let's remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-advocacy",
   "metadata": {},
   "source": [
    "What does this data set look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-thong",
   "metadata": {},
   "source": [
    "_What factors do you think will be the most important?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatypes of columns (float64 => decimal, object => text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summaries of numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values in `native-country` column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-admission",
   "metadata": {},
   "source": [
    "We can also create plots of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot capital losses on a log scale against age\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(income_df['age'], income_df['capital-loss'],\n",
    "          c='black', alpha=0.1)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Capital Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-laundry",
   "metadata": {},
   "source": [
    "Let's split our predictors and response variables. Typically, we call the predictors `X` and the response `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into predictors and response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-amino",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-religious",
   "metadata": {},
   "source": [
    "Our dataset has missing values. Where are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-burst",
   "metadata": {},
   "source": [
    "We have missing values in both numeric and text columns. Let's starting by replacing missing numeric values with the column mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing numeric values with column mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-ghost",
   "metadata": {},
   "source": [
    "For the text columns, there is no mean, so instead we use the column mode (most common value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with column modes\n",
    "for name, values in X.iteritems():\n",
    "    if values.dtype == 'object':\n",
    "        X[name] = values.fillna(values.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-tract",
   "metadata": {},
   "source": [
    "Let's check that all missing values are gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-service",
   "metadata": {},
   "source": [
    "> For a deeper discussion on how to handle missing values, check out [episode 5](https://youtu.be/BIoFwGl2Vtc?t=1150) of WDSS's podcast [DataBasic](https://podcast.wdss.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-child",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-halifax",
   "metadata": {},
   "source": [
    "Machine learning models almost exclusively work with numbers. This means that we need to encode our text columns into a numeric form. There are multiple ways to do this, but the most common is known as one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-infrastructure",
   "metadata": {},
   "source": [
    "![](images/one_hot_enc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-brighton",
   "metadata": {},
   "source": [
    "Lucky for us, `sklearn` has a function for doing exactly this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split numeric and text columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode text colums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recombine variables\n",
    "X_enc = np.hstack((numeric.to_numpy(), text_enc.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new column names\n",
    "enc_columns = np.concatenate([numeric.columns, enc.get_feature_names(text.columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-improvement",
   "metadata": {},
   "source": [
    "What does `X_enc` look like? Notice, it no longer needs to be a dataframe because all of the values are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-wholesale",
   "metadata": {},
   "source": [
    "We also need to encode `y` so that it has value zero if income is over \\$50K and zero otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode y\n",
    "y_enc = (y == '<=50K').astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-subsection",
   "metadata": {},
   "source": [
    "### Train-test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-ideal",
   "metadata": {},
   "source": [
    "How can we make sure that our model isn't overfitting?\n",
    "\n",
    "- We split our dataset into two parts\n",
    "- We train on the first part\n",
    "- Then evaluate on the second part\n",
    "- If the model only memorised the first part, it will be useless on the unseen second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-liberty",
   "metadata": {},
   "source": [
    "We use `sklearn`'s `train_test_split` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets\n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-mounting",
   "metadata": {},
   "source": [
    "Before we fit our model, it is important to have a baseline benchmark. The most simple model we could make would be to ignore the predictors and just predict the most common response for every observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-smooth",
   "metadata": {},
   "source": [
    "Looking at the counts of each value in `y_test` we see that this would have an accuracy of roughly 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-leeds",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-clock",
   "metadata": {},
   "source": [
    "We are now ready to build a model and fit it to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-swing",
   "metadata": {},
   "source": [
    "Finally, we can make predictions on both the training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-samoa",
   "metadata": {},
   "source": [
    "It is also interesting to ask what predictors the model thought were most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "importances = pd.DataFrame({\n",
    "    'feature': enc_columns,\n",
    "    'importance': clf.feature_importances_\n",
    "})\n",
    "importances['predictor'] = importances.feature.str.extract(r'^([^_]+)')\n",
    "importances = importances.groupby('predictor',\n",
    "                                  as_index=False)['importance'].sum()\n",
    "importances.sort_values('importance', inplace=True, ascending=False)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(importances.predictor, importances.importance,\n",
    "       edgecolor='black', color='lightgray')\n",
    "ax.tick_params('x', rotation=45)\n",
    "ax.set_xlabel(\"Feature\")\n",
    "ax.set_ylabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-arrest",
   "metadata": {},
   "source": [
    "## Model Tuning and Measuring Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-compression",
   "metadata": {},
   "source": [
    "We can start by computing train and test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracies\n",
    "print(\"Train set accuracy:\", )\n",
    "print(\"Test set accuracy:\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-bottle",
   "metadata": {},
   "source": [
    "Even better, we can plot a confusion matrix, which shows where our model was making mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "# Train set\n",
    "cm = confusion_matrix(y_train, pred_train)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels = ('<50K', '>=50K'))\n",
    "disp.plot(ax=ax1)\n",
    "ax1.set_title('Train Set Confusion Matrix')\n",
    "# Test set\n",
    "cm = confusion_matrix(y_test, pred_test)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels = ('<50K', '>=50K'))\n",
    "disp.plot(ax=ax2)\n",
    "ax2.set_title('Test Set Confusion Matrix')\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-cannon",
   "metadata": {},
   "source": [
    "It appears that our model is drastically overfitting. This is likely because our trees are too complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-forest",
   "metadata": {},
   "source": [
    "![](images/model_complexity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-tumor",
   "metadata": {},
   "source": [
    "Let's read the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) for `RandomForestClassifier` and try to correct this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-testimony",
   "metadata": {},
   "source": [
    "_How well can you do?_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python for Data Science",
   "language": "python",
   "name": "pyds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
